{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11138848,"sourceType":"datasetVersion","datasetId":6947926}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import zipfile\nimport os\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\n\n# Define transforms\ndef get_transforms():\n    return transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n    ])\n\n# UNet model\nclass UNet(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1):\n        super(UNet, self).__init__()\n        self.enc1 = self.double_conv(in_channels, 64)\n        self.enc2 = self.double_conv(64, 128)\n        self.enc3 = self.double_conv(128, 256)\n        self.enc4 = self.double_conv(256, 512)\n        self.enc5 = self.double_conv(512, 1024)\n\n        self.pool = nn.MaxPool2d(2, 2)\n\n        self.up4 = self.upconv(1024, 512)\n        self.dec4 = self.double_conv(1024, 512)\n\n        self.up3 = self.upconv(512, 256)\n        self.dec3 = self.double_conv(512, 256)\n\n        self.up2 = self.upconv(256, 128)\n        self.dec2 = self.double_conv(256, 128)\n\n        self.up1 = self.upconv(128, 64)\n        self.dec1 = self.double_conv(128, 64)\n\n        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n\n    def double_conv(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def upconv(self, in_channels, out_channels):\n        return nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)\n\n    def forward(self, x):\n        enc1 = self.enc1(x)\n        enc2 = self.enc2(self.pool(enc1))\n        enc3 = self.enc3(self.pool(enc2))\n        enc4 = self.enc4(self.pool(enc3))\n        enc5 = self.enc5(self.pool(enc4))\n\n        x = self.up4(enc5)\n        x = torch.cat([x, enc4], dim=1)\n        x = self.dec4(x)\n\n        x = self.up3(x)\n        x = torch.cat([x, enc3], dim=1)\n        x = self.dec3(x)\n\n        x = self.up2(x)\n        x = torch.cat([x, enc2], dim=1)\n        x = self.dec2(x)\n\n        x = self.up1(x)\n        x = torch.cat([x, enc1], dim=1)\n        x = self.dec1(x)\n\n        return self.final_conv(x)\n\n# Custom Dataset\nclass FaceDataset(Dataset):\n    def __init__(self, csv_file, face_crop_dir, face_segmentation_dir, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.face_crop_dir = face_crop_dir\n        self.face_segmentation_dir = face_segmentation_dir\n        self.transform = transform\n        self.data = self.data[self.data['with_mask'] == 1]\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        img_name = row['filename'].replace('.jpg', '_1.jpg')\n        x1, y1, x2, y2 = row['x1'], row['y1'], row['x2'], row['y2']\n\n        img_path = os.path.join(self.face_crop_dir, img_name)\n        mask_path = os.path.join(self.face_segmentation_dir, img_name)\n\n        if not os.path.exists(img_path) or not os.path.exists(mask_path):\n            return None  # Skip this sample\n\n        try:\n            img = Image.open(img_path).convert('RGB').crop((x1, y1, x2, y2))\n            mask = Image.open(mask_path).convert('L').crop((x1, y1, x2, y2))\n\n            if self.transform:\n                img = self.transform(img)\n                mask = self.transform(mask)\n            return img, mask\n        except:\n            return None  # Handle corrupted or unreadable files\n\n# Collate function to filter out None samples\ndef custom_collate_fn(batch):\n    batch = [b for b in batch if b is not None]\n    return torch.utils.data.dataloader.default_collate(batch)\n\n# Evaluation Metrics\ndef dice_score(pred, target, threshold=0.5):\n    pred = torch.sigmoid(pred) > threshold\n    target = target > threshold\n    intersection = (pred & target).float().sum((1, 2, 3))\n    union = pred.float().sum((1, 2, 3)) + target.float().sum((1, 2, 3))\n    dice = (2. * intersection + 1e-8) / (union + 1e-8)\n    return dice.mean().item()\n\ndef iou_score(pred, target, threshold=0.5):\n    pred = torch.sigmoid(pred) > threshold\n    target = target > threshold\n    intersection = (pred & target).float().sum((1, 2, 3))\n    union = (pred | target).float().sum((1, 2, 3))\n    iou = (intersection + 1e-8) / (union + 1e-8)\n    return iou.mean().item()\n\n# Training loop with validation\ndef train_unet(model, train_loader, val_loader, optimizer, device, num_epochs=3):\n    criterion = nn.BCEWithLogitsLoss()\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0.0\n        for images, masks in train_loader:\n            images, masks = images.to(device), masks.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        model.eval()\n        with torch.no_grad():\n            val_iou, val_dice = 0.0, 0.0\n            for images, masks in val_loader:\n                images, masks = images.to(device), masks.to(device)\n                outputs = model(images)\n                val_iou += iou_score(outputs, masks)\n                val_dice += dice_score(outputs, masks)\n\n        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss:.4f}, \"\n              f\"Val IoU: {val_iou/len(val_loader):.4f}, Val Dice: {val_dice/len(val_loader):.4f}\")\n\n# Paths (modify as needed)\ncsv_file = '/kaggle/input/mfsd-dataset/MSFD/1/dataset.csv'\nface_crop_dir = '/kaggle/input/mfsd-dataset/MSFD/1/face_crop'\nface_segmentation_dir = '/kaggle/input/mfsd-dataset/MSFD/1/face_crop_segmentation'\n\n# Dataset and split\ntransform = get_transforms()\nfull_dataset = FaceDataset(csv_file, face_crop_dir, face_segmentation_dir, transform=transform)\n\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, collate_fn=custom_collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=10, shuffle=False, collate_fn=custom_collate_fn)\n\n# Model setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = UNet(in_channels=3, out_channels=1).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# Train\nprint(\"Running train UNet\")\ntrain_unet(model, train_loader, val_loader, optimizer, device, num_epochs=10)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-24T06:01:14.957217Z","iopub.execute_input":"2025-03-24T06:01:14.957497Z","iopub.status.idle":"2025-03-24T07:40:45.923291Z","shell.execute_reply.started":"2025-03-24T06:01:14.957461Z","shell.execute_reply":"2025-03-24T07:40:45.922274Z"}},"outputs":[{"name":"stdout","text":"Running train UNet\nEpoch 1/10 - Loss: 193.6751, Val IoU: 0.8646, Val Dice: 0.8985\nEpoch 2/10 - Loss: 80.6396, Val IoU: 0.8812, Val Dice: 0.9110\nEpoch 3/10 - Loss: 53.0609, Val IoU: 0.8937, Val Dice: 0.9208\nEpoch 4/10 - Loss: 41.2830, Val IoU: 0.9016, Val Dice: 0.9259\nEpoch 5/10 - Loss: 35.2688, Val IoU: 0.8775, Val Dice: 0.9075\nEpoch 6/10 - Loss: 31.9530, Val IoU: 0.8848, Val Dice: 0.9157\nEpoch 7/10 - Loss: 29.6244, Val IoU: 0.9140, Val Dice: 0.9361\nEpoch 8/10 - Loss: 28.7847, Val IoU: 0.9180, Val Dice: 0.9379\nEpoch 9/10 - Loss: 26.9050, Val IoU: 0.9060, Val Dice: 0.9283\nEpoch 10/10 - Loss: 26.1493, Val IoU: 0.9167, Val Dice: 0.9355\n","output_type":"stream"}],"execution_count":1}]}